{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated Continual learning - SLDA Tutorial (CIFAR-10)\n",
    "Using `tf.data` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TF if not already. We recommend TF2.7 or greater.\n",
    "# !pip install tensorflow==2.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d30942",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441252f7-ed37-4391-a466-7c9ba7054cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %env TF_FORCE_GPU_ALLOW_GROWTH=true # Incremental growth of mem utilization on 'cuda' devices\n",
    "%env CUDA_VISIBLE_DEVICES=\"-1\" # Enforce 'cpu' platform execution\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Callable, Optional, Any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5af671",
   "metadata": {},
   "source": [
    "### Define Decoders class and Image Augment Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Configure data extraction/loading primitives\"\"\"\n",
    "\n",
    "class Decoders:\n",
    "    \"\"\"\n",
    "    Decoders.SIMPLE_DECODER: Simple Image-Label only decoder.\n",
    "\n",
    "    Performant, memory-efficient, allows caching maximum data onto memory\n",
    "\n",
    "    About:\n",
    "    - This decoder only loads `image` and `label` elements\n",
    "    from the TFRecord dataset.\n",
    "    - `image` decoding is skipped, i.e., loaded as a raw string.\n",
    "    - You must decode `image` to `tf.tensor` using a `dataset.map()` function\n",
    "    \"\"\"\n",
    "    SIMPLE_DECODER = tfds.decode.PartialDecoding(\n",
    "          {\n",
    "              'image': True,\n",
    "              'label': True,\n",
    "          },\n",
    "          decoders={\n",
    "              'image': tfds.decode.SkipDecoding(),\n",
    "          })\n",
    "\n",
    "\"\"\"Configure data augmentation while training\"\"\"\n",
    "IMG_AUGMENT_LAYERS = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal')\n",
    "], name='augment_layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d816a18",
   "metadata": {},
   "source": [
    "### SLDA Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb5942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLDA(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Lifelong machine learning with deep streaming Linear Discriminant Analysis.\n",
    "    TL Hayes et. al. (CVPR'20): https://arxiv.org/abs/1909.01520\n",
    "\n",
    "    LDA, at its simplest, is a linear model that learns simple n-dim multivariate\n",
    "    Gaussian for each class with combined single covariance matrix.\n",
    "\n",
    "    It can be interpreted as a Generative Model over **features** rather than high\n",
    "    dimensional input images. Features can be extracted using a backbone\n",
    "    pretrained on ImageNet, for instance.\n",
    "\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Extract features from images using a backbone of your choice\n",
    "    train_features = backbone_model(train_images)\n",
    "    test_features = backbone_model(test_images)\n",
    "\n",
    "    # LDA is a linear model over features as input, mapping to `num_classes` output classes.\n",
    "    # Each feature could be `n_components` dimensional.\n",
    "    slda_model = SLDA(n_components=512, num_classes=10)\n",
    "    slda_model.compile(metrics=['accuracy'])\n",
    "\n",
    "    # SLDA updates mean/covariance 1 sample at a time during training\n",
    "    slda_model.fit(train_features.batch(1))\n",
    "\n",
    "    # Evaluate over test dataset (any batch size works)\n",
    "    slda_model.evaluate(test_features.batch(64))\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components: int, num_classes: int, shrinkage: float = 1e-4):\n",
    "        \"\"\"Instantiate an LDA model.\n",
    "\n",
    "        Args:\n",
    "            n_components (int):\n",
    "              Input 1D feature dimension size.\n",
    "            num_classes (int):\n",
    "              Total output classes.\n",
    "            shrinkage (float, optional):\n",
    "              Shrinkage regularization factor. Defaults to 1e-4.\n",
    "        \"\"\"\n",
    "        super(SLDA, self).__init__()\n",
    "        self.n_components = n_components\n",
    "        self.num_classes = num_classes\n",
    "        self.shrinkage = shrinkage\n",
    "\n",
    "        # Parameters\n",
    "        self.means = self.add_weight(\n",
    "            shape=(self.num_classes, self.n_components),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=False,\n",
    "            name=\"means\",\n",
    "        )\n",
    "        self.counts = self.add_weight(\n",
    "            shape=(self.num_classes,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=False,\n",
    "            name=\"counts\",\n",
    "        )\n",
    "        self.sigma = self.add_weight(\n",
    "            shape=(self.n_components, self.n_components),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=False,\n",
    "            name=\"sigma\",\n",
    "        )\n",
    "        self.sigma_inv = self.add_weight(\n",
    "            shape=tf.shape(self.sigma),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=False,\n",
    "            name=\"sigma_inv\",\n",
    "        )\n",
    "        self._steps = self.add_weight(\n",
    "            shape=(), initializer=\"zeros\", trainable=False, name=\"steps\"\n",
    "        )\n",
    "        self._require_update = tf.Variable(initial_value=1.0, trainable=False)\n",
    "\n",
    "        # Build by call\n",
    "        self(tf.random.uniform((1, self.n_components)))\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        if isinstance(X, tf.data.Dataset):\n",
    "            (x, _) = next(iter(X))\n",
    "            if x.shape[0] > 1:\n",
    "                raise Exception(\n",
    "                    \"batch>1 for training dataset is not supported (expected batch=1)\"\n",
    "                )\n",
    "            super().fit(X, **kwargs)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        \"\"\"Update mean/covariance for the given (x,y) pair\"\"\"\n",
    "        # Unpack\n",
    "        x, y = data\n",
    "\n",
    "        # Calculate scatter\n",
    "        x_minus_mu = x - tf.gather(self.means, y)\n",
    "        scatter = tf.matmul(tf.transpose(x_minus_mu, [1, 0]), x_minus_mu)\n",
    "        delta = scatter * tf.cast(self._steps / (self._steps + 1), tf.float32)\n",
    "\n",
    "        # Update means, counts, sigma\n",
    "        self.sigma.assign(\n",
    "            (tf.cast(self._steps, tf.float32) * self.sigma + delta)\n",
    "            / tf.cast(self._steps + 1, tf.float32)\n",
    "        )\n",
    "        self.means.assign(\n",
    "            tf.tensor_scatter_nd_add(\n",
    "                self.means, [y], x_minus_mu / (tf.gather(self.counts, y) + 1)\n",
    "            )\n",
    "        )\n",
    "        self.counts.assign(tf.tensor_scatter_nd_add(self.counts, [y], [1]))\n",
    "        self._require_update.assign(1.0)\n",
    "        self._steps.assign_add(1)\n",
    "\n",
    "        history = dict()\n",
    "        return history\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        y_pred = self(x)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        history = {m.name: m.result() for m in self.metrics}\n",
    "        return history\n",
    "\n",
    "    @tf.function\n",
    "    def update_inv(self):\n",
    "        \"\"\"Update inverse of regularized covariance\"\"\"\n",
    "        reg_sigma = (1 - self.shrinkage) * self.sigma + self.shrinkage * tf.eye(\n",
    "            tf.shape(self.sigma)[0]\n",
    "        )\n",
    "        self.sigma_inv.assign(tf.linalg.pinv(reg_sigma))\n",
    "        self._require_update.assign(0.0)\n",
    "\n",
    "    @tf.function\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        m_T = tf.transpose(self.means, [1, 0])\n",
    "        W = tf.matmul(self.sigma_inv, m_T)\n",
    "        b = -0.5 * tf.reduce_sum(m_T * W, axis=0)\n",
    "        logits = tf.matmul(x, W) + b\n",
    "        return logits\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Inference step\"\"\"\n",
    "        tf.cond(\n",
    "            tf.cast(self._require_update, tf.bool),\n",
    "            true_fn=lambda: self.update_inv(),\n",
    "            false_fn=lambda: tf.no_op(),\n",
    "        )\n",
    "        return self.forward(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30178a06",
   "metadata": {},
   "source": [
    "### Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230b0ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataset: tf.data.Dataset, model: Any) -> tf.data.Dataset:\n",
    "    \"\"\"Extract feature embeddings from the model for each image in the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (tf.data.Dataset):\n",
    "          A `tf.data.Dataset` instance with raw tensor image keyed as `image` and `label` as label.\n",
    "        model (Any):\n",
    "          A callable of type `tf.keras.Sequential` or `tf.keras.Model` or equivalent that can take `image`\n",
    "          batch as input and return feature embedding.\n",
    "\n",
    "    Returns:\n",
    "        A `tf.data.Dataset` instance with each sample being a `(feature_embedding, label)` tuple\n",
    "    \"\"\"\n",
    "    \n",
    "    features = model.predict(dataset, verbose=1)\n",
    "    labels = np.array(list(dataset.map(lambda x, y: y).unbatch().as_numpy_iterator()))\n",
    "    return tf.data.Dataset.from_tensor_slices({\"image\": features, \"label\": labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf6dc32",
   "metadata": {},
   "source": [
    "### Experiment Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f73ed-d4f7-4bd1-a051-6ea9dc9a708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'cifar10'   # If loading a public TensorFlow dataset\n",
    "\n",
    "IMG_SIZE = (32, 32)\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 16384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## Connect to the Federation\n",
    "\n",
    "Start `Director` and `Envoy` before proceeding with this cell. \n",
    "\n",
    "This cell connects this notebook to the Federation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "cert_dir = 'cert'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50051\n",
    "\n",
    "# Create a Federation\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe22a8",
   "metadata": {},
   "source": [
    "## Query Datasets from Shard Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dbdbd",
   "metadata": {},
   "source": [
    "### Describing FL experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface\n",
    "from openfl.interface.interactive_api.experiment import ModelInterface\n",
    "from openfl.interface.interactive_api.experiment import FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979470",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26642f79-2c55-41ff-a0e8-fbbe5084f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFDS dataset by name (publicly-hosted on TF)\n",
    "(raw_train_ds, raw_test_ds), ds_info = tfds.load(DATASET,\n",
    "                                                 split=['train', 'test'],\n",
    "                                                 with_info=True,\n",
    "                                                 decoders=Decoders.SIMPLE_DECODER)\n",
    "print('About: ', ds_info)\n",
    "print('Element Spec: ', raw_train_ds.element_spec)\n",
    "print('Training samples: ', len(raw_train_ds))\n",
    "print('Testing samples: ', len(raw_test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639e791-734a-479e-8aea-5af4a6553e6b",
   "metadata": {},
   "source": [
    "### Define backbone & feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad82be-5352-45ff-9c64-02a5a9e3e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = tf.keras.applications.EfficientNetV2B0(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(*IMG_SIZE, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "backbone.trainable = False\n",
    "\n",
    "\"\"\"Add augmentation/input layers\"\"\"\n",
    "feature_extractor = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(backbone.input_shape[1:]),\n",
    "    backbone,\n",
    "], name='feature_extractor')\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb6ba1f",
   "metadata": {},
   "source": [
    "### Shard Descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c422fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface\n",
    "from openfl.interface.interactive_api.experiment import ModelInterface\n",
    "from openfl.interface.interactive_api.experiment import FLExperiment\n",
    "from openfl.interface.interactive_api.experiment import DataInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10FedDataset(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        # shard_descriptor.get_split(...) returns a tf.data.Dataset\n",
    "        # Check cifar10_shard_descriptor.py for details\n",
    "        \n",
    "        self.train_set = self._shard_descriptor.get_split('train')\n",
    "        self.valid_set = self._shard_descriptor.get_split('valid')\n",
    "        self.train_size = self._shard_descriptor.get_split('train_size')\n",
    "        self.valid_size = self._shard_descriptor.get_split('test_size')\n",
    "        \n",
    "    def get_train_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract\"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract\"\"\"\n",
    "        return self.valid_set\n",
    "    \n",
    "    def get_train_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return self.train_size\n",
    "\n",
    "    def get_valid_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return self.valid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = CIFAR10FedDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469d9c7-53b0-4e12-9a40-224016914d51",
   "metadata": {},
   "source": [
    "### Model Interface register SLDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942e600-8940-4851-8693-3385c1d48918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = SLDA(n_components=feature_extractor.output_shape[-1],\n",
    "             num_classes=ds_info.features['label'].num_classes)\n",
    "\n",
    "model.compile(metrics=['accuracy'])\n",
    "\n",
    "# Create ModelInterface\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=None, framework_plugin=framework_adapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af4c98",
   "metadata": {},
   "source": [
    "### Define Aggregation Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Federated SLDA Model Aggregation module.\"\"\"\n",
    "\n",
    "from openfl.interface.aggregation_functions.core import AggregationFunction\n",
    "\n",
    "class FedSLDAAggregation(AggregationFunction):\n",
    "    \"\"\"FL SLDA aggregation.\"\"\"\n",
    "\n",
    "    def call(\n",
    "        self, local_tensors, db_iterator, tensor_name, fl_round, tags\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Aggregate tensors.\n",
    "\n",
    "        Args:\n",
    "            local_tensors(list[openfl.utilities.LocalTensor]): List of local tensors to aggregate.\n",
    "            db_iterator: iterator over history of all tensors. Columns:\n",
    "                - 'tensor_name': name of the tensor.\n",
    "                    Examples for `torch.nn.Module`s: 'conv1.weight', 'fc2.bias'.\n",
    "                - 'round': 0-based number of round corresponding to this tensor.\n",
    "                - 'tags': tuple of tensor tags. Tags that can appear:\n",
    "                    - 'model' indicates that the tensor is a model parameter.\n",
    "                    - 'trained' indicates that tensor is a part of a training result.\n",
    "                        These tensors are passed to the aggregator node after local learning.\n",
    "                    - 'aggregated' indicates that tensor is a result of aggregation.\n",
    "                        These tensors are sent to collaborators for the next round.\n",
    "                    - 'delta' indicates that value is a difference between rounds\n",
    "                        for a specific tensor.\n",
    "                    also one of the tags is a collaborator name\n",
    "                    if it corresponds to a result of a local task.\n",
    "\n",
    "                - 'nparray': value of the tensor.\n",
    "            tensor_name: name of the tensor\n",
    "            fl_round: round number\n",
    "            tags: tuple of tags for this tensor\n",
    "        Returns:\n",
    "            np.ndarray: aggregated tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        # Mean of mean\n",
    "        if \"means:0\" in tensor_name:\n",
    "            weighted_mean = np.sum(np.array([x.tensor * x.weight for x in local_tensors]), axis=0)\n",
    "            return weighted_mean\n",
    "        \n",
    "        # Add up sigma\n",
    "        if \"sigma:0\" in tensor_name:\n",
    "            sigma = np.sum(np.array([x.tensor for x in local_tensors]), axis=0)\n",
    "            return sigma\n",
    "\n",
    "        # aggregation not needed for 'count', 'variables' & 'step.\n",
    "        # But still, now that these parameters are considered trainable and as a part of update, some consolidation is required?\n",
    "        # Or can we not call this as a trainable parameter?\n",
    "        # Currently returning mean of 'count', 'variables' & 'step. doesn't make sense!\n",
    "        tensors = np.array([x.tensor for x in local_tensors])\n",
    "        return np.mean(tensors, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c165b",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9649385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "agg_fn = FedSLDAAggregation()\n",
    "TI = TaskInterface()\n",
    "\n",
    "task_params = {\n",
    "        'n_components': feature_extractor.output_shape[-1],\n",
    "        'n_classes': ds_info.features['label'].num_classes\n",
    "    }\n",
    "\n",
    "@TI.add_kwargs(**task_params)\n",
    "@TI.register_fl_task(model='model', data_loader='dataset', optimizer='optimizer', device='device')\n",
    "@TI.set_aggregation_function(agg_fn)\n",
    "def train(model, dataset, optimizer, device, n_components, n_classes, warmup=False):\n",
    "    res_model = SLDA(n_components, n_classes)\n",
    "    res_model.set_weights(model.get_weights())\n",
    "    res_model.compile(metrics=['accuracy'])\n",
    "    res_model.fit(dataset, epochs=1)\n",
    "    train_acc = res_model.evaluate(dataset.unbatch().batch(128))\n",
    "    \n",
    "    # Exit\n",
    "    model.set_weights(res_model.get_weights())\n",
    "    return {'train_acc': train_acc,}\n",
    "\n",
    "\n",
    "@TI.add_kwargs(**task_params)\n",
    "@TI.register_fl_task(model='model', data_loader='dataset', device='device')\n",
    "@TI.set_aggregation_function(agg_fn)\n",
    "def validate(model, dataset, device, n_components, n_classes):\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    res_model = SLDA(n_components, n_classes)\n",
    "    res_model.set_weights(model.get_weights())\n",
    "    res_model.compile(metrics=['accuracy'])\n",
    "    \n",
    "    val_acc = res_model.evaluate(dataset)\n",
    "    return {'validation_accuracy': val_acc,}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'cifar10_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44de9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "ROUNDS_TO_TRAIN = 5\n",
    "fl_experiment.start(model_provider=MI,\n",
    "                   task_keeper=TI,\n",
    "                   data_loader=fed_dataset,\n",
    "                   rounds_to_train=ROUNDS_TO_TRAIN,\n",
    "                   opt_treatment='CONTINUE_GLOBAL', )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fc5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.stream_metrics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flclenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "edf02b173dfeb5dc10ca2aee2559a035382f5d19c2fb6824656a63defbe5b135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
