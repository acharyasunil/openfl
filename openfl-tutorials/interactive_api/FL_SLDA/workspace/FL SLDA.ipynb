{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated SLDA TF.Data and Custom Dataset Tutorial\n",
    "Using `tf.data` API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1329f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TF if not already. We recommend TF2.7 or greater.\n",
    "# !pip install tensorflow==2.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d30942",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441252f7-ed37-4391-a466-7c9ba7054cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 18:15:01.653252: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/sunilach/flclenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-11-29 18:15:03.195954: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-29 18:15:03.723960: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-11-29 18:15:03.724011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15726 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:18:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Config/Options\n",
    "from openfl.cl.config import Decoders\n",
    "from openfl.cl.config import IMG_AUGMENT_LAYERS\n",
    "\n",
    "# Model/Loss definitions\n",
    "from openfl.cl.models.slda import SLDA\n",
    "from openfl.cl.models import losses\n",
    "from openfl.cl.models.utils import extract_features\n",
    "\n",
    "# Dataset handling (synthesize/build/query)\n",
    "from openfl.cl.lib.dataset.repository import DatasetRepository\n",
    "from openfl.cl.lib.dataset.utils import as_tuple, decode_example, get_label_distribution\n",
    "from openfl.cl.lib.dataset.synthesizer import synthesize_by_sharding_over_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0833dfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a69ac1b-115c-4e4b-99c5-e7471d17ffb7",
   "metadata": {},
   "source": [
    "Experiment Options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "967f73ed-d4f7-4bd1-a051-6ea9dc9a708b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'cifar10'   # If loading a public TensorFlow dataset\n",
    "# DATASET = '/tmp/repository/vege'  # If loading a local TFRecord dataset\n",
    "\n",
    "IMG_SIZE = (32, 32)\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE_BUFFER = 16384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## Connect to the Federation\n",
    "\n",
    "Start `Director` and `Envoy` before proceeding with this cell. \n",
    "\n",
    "This cell connects this notebook to the Federation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "cert_dir = 'cert'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50051\n",
    "\n",
    "# Create a Federation\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe22a8",
   "metadata": {},
   "source": [
    "## Query Datasets from Shard Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ENVS1': {'shard_info': node_info {\n",
       "    name: \"ENVS1\"\n",
       "  }\n",
       "  shard_description: \"CIFAR10 dataset, shard number 1/2.\\nSamples [Train/Valid]: [25000/10000]\"\n",
       "  sample_shape: \"32\"\n",
       "  sample_shape: \"32\"\n",
       "  sample_shape: \"3\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-11-29 18:14:31',\n",
       "  'current_time': '2022-11-29 18:15:04',\n",
       "  'valid_duration': seconds: 120,\n",
       "  'experiment_name': 'ExperimentName Mock'},\n",
       " 'ENVS2': {'shard_info': node_info {\n",
       "    name: \"ENVS2\"\n",
       "  }\n",
       "  shard_description: \"CIFAR10 dataset, shard number 2/2.\\nSamples [Train/Valid]: [25000/10000]\"\n",
       "  sample_shape: \"32\"\n",
       "  sample_shape: \"32\"\n",
       "  sample_shape: \"3\"\n",
       "  target_shape: \"1\",\n",
       "  'is_online': True,\n",
       "  'is_experiment_running': False,\n",
       "  'last_updated': '2022-11-29 18:14:42',\n",
       "  'current_time': '2022-11-29 18:15:04',\n",
       "  'valid_duration': seconds: 120,\n",
       "  'experiment_name': 'ExperimentName Mock'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a6c237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sample shape: (32, 32, 3), target shape: (1,)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dbdbd",
   "metadata": {},
   "source": [
    "## Describing FL experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc88700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface\n",
    "from openfl.interface.interactive_api.experiment import ModelInterface\n",
    "from openfl.interface.interactive_api.experiment import FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979470",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26642f79-2c55-41ff-a0e8-fbbe5084f378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About:  tfds.core.DatasetInfo(\n",
      "    name='cifar10',\n",
      "    full_name='cifar10/3.0.2',\n",
      "    description=\"\"\"\n",
      "    The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
      "    \"\"\",\n",
      "    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',\n",
      "    data_path='/home/sunilach/tensorflow_datasets/cifar10/3.0.2',\n",
      "    download_size=162.17 MiB,\n",
      "    dataset_size=132.40 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'id': Text(shape=(), dtype=tf.string),\n",
      "        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=50000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@TECHREPORT{Krizhevsky09learningmultiple,\n",
      "        author = {Alex Krizhevsky},\n",
      "        title = {Learning multiple layers of features from tiny images},\n",
      "        institution = {},\n",
      "        year = {2009}\n",
      "    }\"\"\",\n",
      ")\n",
      "Element Spec:  {'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n",
      "Training samples:  50000\n",
      "Testing samples:  10000\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"Load the dataset: Public or Local\"\"\"\n",
    "# if tf.io.gfile.isdir(DATASET):\n",
    "#     repo = DatasetRepository(data_dir=DATASET)\n",
    "#     builder = repo.get_builder()  # Builds all versions by default\n",
    "#     ds_info = builder.info\n",
    "#     (raw_train_ds, raw_test_ds) = builder.as_dataset(split=['train', 'test'],\n",
    "#                                                      decoders=Decoders.SIMPLE_DECODER)\n",
    "# else:\n",
    "# Load TFDS dataset by name (publicly-hosted on TF)\n",
    "(raw_train_ds, raw_test_ds), ds_info = tfds.load(DATASET,\n",
    "                                                 split=['train', 'test'],\n",
    "                                                 with_info=True,\n",
    "                                                 decoders=Decoders.SIMPLE_DECODER)\n",
    "print('About: ', ds_info)\n",
    "print('Element Spec: ', raw_train_ds.element_spec)\n",
    "print('Training samples: ', len(raw_train_ds))\n",
    "print('Testing samples: ', len(raw_test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5639e791-734a-479e-8aea-5af4a6553e6b",
   "metadata": {},
   "source": [
    "Define Feature Extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ad82be-5352-45ff-9c64-02a5a9e3e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"feature_extractor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b0 (Function  (None, 1280)             5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,919,312\n",
      "Trainable params: 0\n",
      "Non-trainable params: 5,919,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "backbone = tf.keras.applications.EfficientNetV2B0(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(*IMG_SIZE, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "backbone.trainable = False\n",
    "\n",
    "\"\"\"Add augmentation/input layers\"\"\"\n",
    "feature_extractor = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(backbone.input_shape[1:]),\n",
    "    backbone,\n",
    "], name='feature_extractor')\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c9eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import DataInterface\n",
    "\n",
    "class CIFAR10FedDataset(DataInterface):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "\n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        \n",
    "        # shard_descriptor.get_split(...) returns a tf.data.Dataset\n",
    "        # Check cifar10_shard_descriptor.py for details\n",
    "        \n",
    "        self.train_set = self._shard_descriptor.get_split('train')\n",
    "        self.valid_set = self._shard_descriptor.get_split('valid')\n",
    "        self.train_size = self._shard_descriptor.get_split('train_size')\n",
    "        self.valid_size = self._shard_descriptor.get_split('test_size')\n",
    "        \n",
    "    def get_train_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract\"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract\"\"\"\n",
    "        return self.valid_set\n",
    "    \n",
    "    def get_train_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return self.train_size\n",
    "\n",
    "    def get_valid_data_size(self) -> int:\n",
    "        \"\"\"Information for aggregation\"\"\"\n",
    "        return self.valid_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfb459",
   "metadata": {},
   "source": [
    "### Create CIFAR10 federated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af5c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = CIFAR10FedDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b469d9c7-53b0-4e12-9a40-224016914d51",
   "metadata": {},
   "source": [
    "### Register Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4942e600-8940-4851-8693-3385c1d48918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE BUILD SLDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 18:15:06.360415: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x1caa7620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER BUILD SLDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 18:15:07.830594: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "source": [
    "model = SLDA(n_components=feature_extractor.output_shape[-1],\n",
    "             num_classes=ds_info.features['label'].num_classes)\n",
    "\n",
    "model.compile(metrics=['accuracy'])\n",
    "# Create ModelInterface\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.keras_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=None, framework_plugin=framework_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff53a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66509498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://70a00af8-e427-4082-87e7-37b43bf72701/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://70a00af8-e427-4082-87e7-37b43bf72701/assets\n"
     ]
    }
   ],
   "source": [
    "res_model = copy.deepcopy(model)\n",
    "res_model.compile(metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c165b",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9649385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "TI = TaskInterface()\n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='dataset', optimizer='optimizer', device='device')     \n",
    "def train(model, dataset, optimizer, device, warmup=False):\n",
    "#     print(\"Train Task inside DEF\")\n",
    "#     print(model.weights)\n",
    "#     print(type(model))\n",
    "#     print(type(res_model))\n",
    "    res_model.__class__ = SLDA\n",
    "#     print(type(res_model))\n",
    "    res_model.set_weights(model.get_weights())\n",
    "#     print(res_model.weights)\n",
    "#     model.compile(metrics=['accuracy'])\n",
    "#     print(\"After Train Compile\")\n",
    "    res_model.fit(dataset, epochs=1)\n",
    "#     print(\"Train Task Fit Done\")\n",
    "#     print(res_model.weights)\n",
    "    model.set_weights(res_model.get_weights())\n",
    "#     print(model.weights)\n",
    "    train_acc = model.evaluate(dataset)\n",
    "    print(\"Train Accuracy\")\n",
    "    print(train_acc)\n",
    "    return {'train_acc': train_acc[1],}\n",
    "\n",
    "\n",
    "@TI.register_fl_task(model='model', data_loader='dataset', device='device')     \n",
    "def validate(model, dataset, device):\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "#     print(\"Validate Task inside DEF\")\n",
    "#     print(model.weights)\n",
    "#     print(type(model))\n",
    "#     print(\"After Validate Compile\")\n",
    "    val_acc = model.evaluate(dataset)\n",
    "#     print(val_acc)\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc[1]),))\n",
    "    return {'validation_accuracy': val_acc[1],}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "experiment_name = 'cifar10_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41b44de9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeRIALIZING\n",
      "model_interface_file\n",
      "INFO:tensorflow:Assets written to: ram://f35c9273-9edc-4dad-b259-631e63d485d1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://f35c9273-9edc-4dad-b259-631e63d485d1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeRIALIZING\n",
      "tasks_interface_file\n",
      "INFO:tensorflow:Assets written to: ram://d59c7ae0-3f53-4f55-a9b8-f2b8c9902910/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d59c7ae0-3f53-4f55-a9b8-f2b8c9902910/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SeRIALIZING\n",
      "dataloader_interface_file\n",
      "SeRIALIZING\n",
      "aggregation_function_interface_file\n",
      "SeRIALIZING\n",
      "task_assigner_file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:openfl.federated.task.task_runner:tried to remove tensor: __opt_state_needed not present in the tensor dict\n",
      "WARNING:openfl.interface.interactive_api.experiment:tried to remove tensor: __opt_state_needed not present in the tensor dict\n"
     ]
    }
   ],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "ROUNDS_TO_TRAIN = 2\n",
    "fl_experiment.start(model_provider=MI,\n",
    "                   task_keeper=TI,\n",
    "                   data_loader=fed_dataset,\n",
    "                   rounds_to_train=ROUNDS_TO_TRAIN,\n",
    "                   opt_treatment='CONTINUE_GLOBAL', )\n",
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2559c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "50f96e42274e6c5243b63a33fbf7578ef10c4dac29a09d4747c12b7618b0d3bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
