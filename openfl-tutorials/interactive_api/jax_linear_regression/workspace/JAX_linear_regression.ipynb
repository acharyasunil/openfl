{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b652a9-02d6-4229-adc1-d16d48839853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements.txt excludes jaxlib, as it has a CUDA and cuDNN dependency.\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb48a-e902-4c5a-a7b7-39728f845707",
   "metadata": {},
   "source": [
    "Run this jupyter notebook on a virtual environment. Pick the jax version compatible with the CUDA and cuDNN installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d13f5b-0933-4e14-807d-ebebd42c1165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip # Careful with the pip upgrade, it may cause a package dependency related problems during OpenFL workflow execution.\n",
    "\n",
    "# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n",
    "# Note: wheels only available on linux.\n",
    "# !pip install --upgrade \"jax[cuda]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "\n",
    "# Installs the wheel compatible with Cuda >= 11.4 and cudnn >= 8.2\n",
    "!pip install \"jax[cuda11_cudnn82]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html\n",
    "\n",
    "# Installs the wheel compatible with Cuda >= 11.1 and cudnn >= 8.0.5\n",
    "# !pip install \"jax[cuda11_cudnn805]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615610e-673c-4830-9872-a2e157844f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without either of the below flags, JAX XLA raised CUDA_OUT_OF_MEMORY exception.\n",
    "# JAX XLA pre-allocates 90% of the GPU at start\n",
    "\n",
    "# Below flag to restrict max GPU allocation to 50%\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=.5\n",
    "\n",
    "# OR\n",
    "\n",
    "# set XLA_PYTHON_CLIENT_PREALLOCATE to false to incrementally allocate GPU memory as and when required. But can take entire GPU by the end.\n",
    "# %env XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e64c6-9955-4afc-8d04-d8c85bb28edc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression with JAX and OpenFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b208c1-8160-47d1-b9b3-ae4cc8f4c367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7, 5\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import make_jaxpr\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b334ef-6a72-4b82-b978-1401973d0512",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Simple Linear Regression\n",
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq5-1.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f3e7f1-27d9-4eb7-bdc3-7a5125288553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with n_features\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Train test split - Default 0.75/0.25\n",
    "X, X_test, y, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b054bd70-1832-410f-803a-019c8d87f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both the MSE function are optimal and accurate in terms of correctness.\n",
    "\n",
    "# Calculate MSE approach 1\n",
    "def mse_loss_function1(W, X, y):\n",
    "    y_pred = jnp.dot(X, W)\n",
    "    mse_error = y_pred - y\n",
    "    return jnp.mean(jnp.square(mse_error))\n",
    "\n",
    "# Calculate MSE approach 2\n",
    "def mse_loss_function2(W, X, Y):\n",
    "    def squared_error(x, y):\n",
    "        y_pred = jnp.dot(x, W)\n",
    "        return jnp.inner(y-y_pred, y-y_pred)\n",
    "    vectorized_square_error = jax.vmap(squared_error)\n",
    "    return jnp.mean(vectorized_square_error(X, Y), axis=0)\n",
    "\n",
    "# Weight update, JAX compiled function. Consequent executions are way faster!!!.\n",
    "def update(W, x, y, lr):\n",
    "    W = W - lr * jax.grad(mse_loss_function1)(W, x, y)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57b5e1f-5f55-46bf-96b4-08bc398088e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX logical execution plan\n",
    "print(jax.make_jaxpr(update)(jnp.ones(X.shape[1]), X, y, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb5eef3-2a96-4610-9fdb-68581b8634e1",
   "metadata": {},
   "source": [
    "Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27639ff-4303-49fc-a82b-56e4759665f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, n_feat: int) -> None:\n",
    "        self.weights = jnp.ones(n_feat)\n",
    "        self.history = None\n",
    "    \n",
    "    def mse(self, X, y) -> float:\n",
    "        return mse_loss_function1(self.weights, X, y)\n",
    " \n",
    "    def predict(self, X):\n",
    "        return jnp.dot(X, self.weights)\n",
    "    \n",
    "    def fit(self, X, Y, n_epochs : int, learning_rate : int, silent : bool) -> None:\n",
    "        \n",
    "        # Speed up weight updates with consecutive calls to jitted `update` function.\n",
    "        update_weights = jax.jit(update)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        print('Training Loss at start: ', self.mse(X, Y))\n",
    "        for i in range(n_epochs):\n",
    "            self.weights = update_weights(self.weights, X, y, learning_rate)\n",
    "            if i % int(epochs/10) == 0 and not silent:\n",
    "                print(str(i), 'Training Loss: ', self.mse(X, Y))\n",
    "\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6afbbb-7c3f-48a9-8221-8e186891bd8f",
   "metadata": {},
   "source": [
    "Visualize data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66394bd-23de-42ae-937a-2a246332d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e7c99-192d-4389-8f5b-55eb83104a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.scatter(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb812db-971e-4b25-83a8-86bfa901af11",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Linear Regression Model without federeation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefca2b-d7f6-4111-8872-c017c182a2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X.shape -> (n_samples, n_features)\n",
    "\n",
    "lr_model = LinearRegression(X.shape[1])\n",
    "lr = 0.01\n",
    "epochs = 101\n",
    "\n",
    "print(f\"Initial Test MSE: {lr_model.mse(X_test,y_test)}\")\n",
    "\n",
    "# silent: logging verbosity\n",
    "lr_model.fit(X,y, epochs, lr, silent=False)\n",
    "\n",
    "print(f\"Final Test MSE: {lr_model.mse(X_test,y_test)}\")\n",
    "\n",
    "print(f\"Final parameters: {lr_model.weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd4d2d7-5537-496a-88c1-301da87d979c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now we run the same training on federated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf7090-da51-4f4e-9d28-2a5c6e3bca02",
   "metadata": {},
   "source": [
    "## Connect to a Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c0039-e1f7-4047-b98b-a2d4bd42f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50050\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815120e-b704-4a7d-a65a-3c7542023ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011dd95-64a7-4a8b-91ec-e61cdf885bbb",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1985ac9-a2b1-4561-a962-6adfe35c3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "\n",
    "class LinearRegressionDataSet(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize DataLoader.\"\"\"\n",
    "        self.kwargs = kwargs\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        \"\"\"Return shard descriptor.\"\"\"\n",
    "        return self._shard_descriptor\n",
    "    \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "        \n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self.train_set = shard_descriptor.get_dataset(\"train\")\n",
    "        self.val_set = shard_descriptor.get_dataset(\"val\")\n",
    "\n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
    "        return self.val_set\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.val_set)\n",
    "    \n",
    "lin_reg_dataset = LinearRegressionDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8909127-99d1-4dba-86fe-01a1b86585e7",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523c9a2-a259-461f-937f-1fb054bd2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'custom_adapter.CustomFrameworkAdapter'\n",
    "\n",
    "fed_model = LinearRegression(X.shape[1])\n",
    "MI = ModelInterface(model=fed_model, optimizer=None, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = LinearRegression(X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3558bb-b21b-48ac-b07e-43cf75e6907b",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e1ff9-d54a-49b5-9ce8-8bc72c6a2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "@TI.add_kwargs(**{'lr': 0.01,\n",
    "                   'epochs': 101})\n",
    "@TI.register_fl_task(model='my_model', data_loader='train_data', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(my_model, train_data, optimizer, device, lr, epochs):\n",
    "    X, Y = train_data[:,:-1], train_data[:,-1]\n",
    "    my_model.fit(X, Y, epochs, lr, silent=False)\n",
    "    return {'train_MSE': my_model.mse(X, Y),}\n",
    "\n",
    "@TI.register_fl_task(model='my_model', data_loader='val_data', device='device')\n",
    "def validate(my_model, val_data, device):\n",
    "    X, Y = val_data[:,:-1], val_data[:,-1] \n",
    "    return {'validation_MSE': my_model.mse(X, Y),}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7659cc-6e03-43f5-9078-95707fa0e4d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749100e8-05ce-418c-a980-545e3beb900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'jax_linear_regression_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf1df7-8ca8-4a5e-a833-47c265c11e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.start(model_provider=MI,\n",
    "                    task_keeper=TI,\n",
    "                    data_loader=lin_reg_dataset,\n",
    "                    rounds_to_train=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178d1ea-05e6-46be-ac07-21620bd6ec76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af331ccd-66b4-4925-8627-52cf03ceea5e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optional: start tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde4ed4d-dda5-4bab-8dd3-e1ac44f5acf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script /bin/bash --bg\n",
    "tensorboard --host $(hostname --all-fqdns | awk '{print $1}') --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9e4e2-c4b5-4dd4-8ca2-61e99a3fff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# tensorboard --logdir <dir>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa78602-b66a-4378-bea9-e915f2a1fdd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_model = fl_experiment.get_last_model()\n",
    "best_model = fl_experiment.get_best_model()\n",
    "print(best_model.weights)\n",
    "print(last_model.weights)\n",
    "print(f\"last model MSE: {last_model.mse(X,y)}\")\n",
    "print(f\"best model MSE: {best_model.mse(X,y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb23aef-6ea7-487b-ab15-2dc8329001a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
