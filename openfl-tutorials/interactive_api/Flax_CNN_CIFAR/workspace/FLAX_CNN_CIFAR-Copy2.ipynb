{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6705776d-d264-493d-9696-7623231e558a",
   "metadata": {},
   "source": [
    "# FLAX Convolution Neural Network Example - Interactive API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fb48a-e902-4c5a-a7b7-39728f845707",
   "metadata": {},
   "source": [
    "Run this jupyter notebook on a virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42945f9c-081f-48a0-871c-d0c0f6b4103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c195d51-2499-4a00-9bee-97dc5f79d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade -q \"jax[cuda11_cudnn805]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "# !pip install --upgrade -q git+https://github.com/google/flax.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd66b4cd-03c2-4dc6-9113-0c3fc309e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flax==0.4.1 ml_collections optax jax==0.3.13 -q\n",
    "# # jaxlib==0.3.10 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95eeb4-9a6b-401d-9d35-2deaa4b51860",
   "metadata": {},
   "source": [
    "GPU version of JAX. Pick the jax version compatible with the CUDA and cuDNN pre-installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e0e9cff-71f9-4710-87ae-cc5c37925008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip # Careful with the pip upgrade, it may cause a package dependency related problems during OpenFL workflow execution.\n",
    "\n",
    "# Installs the wheel compatible with CUDA 11 and cuDNN 8.2 or newer.\n",
    "# Note: wheels only available on linux.\n",
    "# !pip install -U jaxlib==0.3.10+cuda11.cudnn82 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# Installs the wheel compatible with Cuda >= 11.4 and cudnn >= 8.2\n",
    "# !pip install -U jax[cuda11_cudnn82] -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "\n",
    "# Installs the wheel compatible with Cuda >= 11.1 and cudnn >= 8.0.5\n",
    "# !pip install \"jax[cuda11_cudnn805]\" -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3fcc5b-ee99-4ea8-95e8-6ce08db00809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=.8\n"
     ]
    }
   ],
   "source": [
    "# Without either of the below flags, JAX XLA raised CUDA_OUT_OF_MEMORY exception.\n",
    "# JAX XLA pre-allocates 90% of the GPU at start\n",
    "\n",
    "# Below flag to restrict max GPU allocation to 80%\n",
    "# %env XLA_PYTHON_CLIENT_MEM_FRACTION=.8\n",
    "\n",
    "# OR\n",
    "\n",
    "# set XLA_PYTHON_CLIENT_PREALLOCATE to false to incrementally allocate GPU memory as and when required. But can take entire GPU by the end.\n",
    "# %env XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c768ad39-ba4e-4a2c-a7b4-dbbc3ac729a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow==2.8.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c168bf1-3b4b-4745-bfd2-ee232e6776cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install tensorflow_datasets ml_collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba6fd71-e66e-4103-a76d-51ed591fc65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SHELL': '/bin/bash',\n",
       " 'COLORTERM': 'truecolor',\n",
       " 'no_proxy': 'localhost,127.0.0.0/8,10.0.0.0/8,.intel.com',\n",
       " 'TERM_PROGRAM_VERSION': '1.69.2',\n",
       " 'LANGUAGE': 'en_IN:en',\n",
       " 'PWD': '/home/sunilach/openfl/forked-intel-openfl/openfl-tutorials/interactive_api/Flax_CNN_CIFAR/workspace',\n",
       " 'LOGNAME': 'sunilach',\n",
       " 'XDG_SESSION_TYPE': 'tty',\n",
       " 'ftp_proxy': 'ftp://proxy.iind.intel.com:1080/',\n",
       " 'MOTD_SHOWN': 'pam',\n",
       " 'HOME': '/home/sunilach',\n",
       " 'LANG': 'en_US.UTF-8',\n",
       " 'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:',\n",
       " 'VIRTUAL_ENV': '/home/sunilach/openflenv',\n",
       " 'https_proxy': 'http://proxy-us.intel.com:911',\n",
       " 'SSH_CONNECTION': '10.213.75.6 59927 10.106.37.52 22',\n",
       " 'socks_proxy': 'socks://proxy.jf.intel.com:1080/',\n",
       " 'LESSCLOSE': '/usr/bin/lesspipe %s %s',\n",
       " 'XDG_SESSION_CLASS': 'user',\n",
       " 'TERM': 'xterm-color',\n",
       " 'LESSOPEN': '| /usr/bin/lesspipe %s',\n",
       " 'USER': 'sunilach',\n",
       " 'VSCODE_GIT_IPC_HANDLE': '/run/user/1004/vscode-git-4d9cc468c6.sock',\n",
       " 'SHLVL': '1',\n",
       " 'XDG_SESSION_ID': '2',\n",
       " 'http_proxy': 'http://proxy-us.intel.com:911',\n",
       " 'LD_LIBRARY_PATH': '/usr/local/cuda/lib64:/usr/local/cuda/lib64',\n",
       " 'XDG_RUNTIME_DIR': '/run/user/1004',\n",
       " 'PS1': '(openflenv) ${debian_chroot:+($debian_chroot)}\\\\[\\\\033[01;32m\\\\]\\\\u@\\\\h\\\\[\\\\033[00m\\\\]:\\\\[\\\\033[01;34m\\\\]\\\\w\\\\[\\\\033[01;31m\\\\]$(parse_git_branch)\\\\[\\\\033[00m\\\\]\\\\$ ',\n",
       " 'SSH_CLIENT': '10.213.75.6 59927 22',\n",
       " 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop',\n",
       " 'BROWSER': '/home/sunilach/.vscode-server/bin/3b889b090b5ad5793f524b5d1d39fda662b96a2a/bin/helpers/browser.sh',\n",
       " 'PATH': '/home/sunilach/openflenv/bin:/usr/local/cuda/bin:/home/sunilach/.vscode-server/bin/3b889b090b5ad5793f524b5d1d39fda662b96a2a/bin/remote-cli:/home/sunilach/.local/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin$$',\n",
       " 'DBUS_SESSION_BUS_ADDRESS': 'unix:path=/run/user/1004/bus',\n",
       " 'TERM_PROGRAM': 'vscode',\n",
       " 'VSCODE_IPC_HOOK_CLI': '/run/user/1004/vscode-ipc-83e6a249-695b-4479-ac65-d013d3c12845.sock',\n",
       " 'OLDPWD': '/home/sunilach/openfl/forked-intel-openfl/openfl-tutorials/interactive_api/Flax_CNN_CIFAR',\n",
       " '_': '/home/sunilach/openflenv/bin/jupyter',\n",
       " 'JPY_PARENT_PID': '29202',\n",
       " 'CLICOLOR': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://matplotlib_inline.backend_inline',\n",
       " 'TF_FORCE_GPU_ALLOW_GROWTH': 'true'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9008000e-fe07-4ff5-91cf-facb2decc560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunilach/openflenv/lib/python3.8/site-packages/chex/_src/pytypes.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n",
      "/home/sunilach/openflenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "from flax.metrics import tensorboard\n",
    "from flax.training import train_state\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import ml_collections\n",
    "import optax\n",
    "import tensorflow_datasets as tfds\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d292230e-bc1d-423d-836d-b4630a1c4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Both the MSE function are optimal and accurate in terms of correctness.\n",
    "\n",
    "# # Calculate MSE approach 1\n",
    "# def mse_loss_function1(W, X, y):\n",
    "#     y_pred = jnp.dot(X, W)\n",
    "#     mse_error = y_pred - y\n",
    "#     return jnp.mean(jnp.square(mse_error))\n",
    "\n",
    "# # Calculate MSE approach 2\n",
    "# def mse_loss_function2(W, X, Y):\n",
    "#     def squared_error(x, y):\n",
    "#         y_pred = jnp.dot(x, W)\n",
    "#         return jnp.inner(y-y_pred, y-y_pred)|\n",
    "#     vectorized_square_error = jax.vmap(squared_error)\n",
    "#     return jnp.mean(vectorized_square_error(X, Y), axis=0)\n",
    "\n",
    "# # Weight update, JAX compiled function. Consequent executions are way faster!!!.\n",
    "# def update(W, x, y, lr):\n",
    "#     W = W - lr * jax.grad(mse_loss_function1)(W, x, y)\n",
    "#     return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d505d6-fe2d-4a75-844a-6b1ca0280ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_relpaths = ('configs/default.py', 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cca4d46-dc93-4897-b477-a22b042d1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def apply_model(state, images, labels):\n",
    "    \"\"\"Computes gradients, loss and accuracy for a single batch.\"\"\"\n",
    "\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn({'params': params}, images)\n",
    "        one_hot = jax.nn.one_hot(labels, 10)\n",
    "        loss = jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
    "        return loss, logits\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, logits), grads = grad_fn(state.params)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "    return grads, loss, accuracy\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def update_model(state, grads):\n",
    "    return state.apply_gradients(grads=grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9693c2c0-1330-4df9-bbf8-3beaf0cc14db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(state, train_ds, batch_size, rng):\n",
    "    \"\"\"Train for a single epoch.\"\"\"\n",
    "    train_ds_size = len(train_ds['image'])\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "    perms = jax.random.permutation(rng, len(train_ds['image']))\n",
    "    perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "    perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_accuracy = []\n",
    "\n",
    "    for perm in perms:\n",
    "        batch_images = train_ds['image'][perm, ...]\n",
    "        batch_labels = train_ds['label'][perm, ...]\n",
    "        grads, loss, accuracy = apply_model(state, batch_images, batch_labels)\n",
    "        state = update_model(state, grads)\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_accuracy.append(accuracy)\n",
    "        \n",
    "    train_loss = np.mean(epoch_loss)\n",
    "    train_accuracy = np.mean(epoch_accuracy)\n",
    "    return state, train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6e705b-80e3-454d-bd35-8294e201c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(config: ml_collections.ConfigDict,\n",
    "                       workdir: str) -> train_state.TrainState:\n",
    "    \"\"\"Execute model training and evaluation loop.\n",
    "    Args:\n",
    "        config: Hyperparameter configuration for training and evaluation.\n",
    "        workdir: Directory where the tensorboard summaries are written to.\n",
    "    Returns:\n",
    "        The train state (which includes the `.params`).\n",
    "    \"\"\"\n",
    "    \n",
    "    train_ds, test_ds = get_datasets()\n",
    "    rng = jax.random.PRNGKey(0)\n",
    "\n",
    "    summary_writer = tensorboard.SummaryWriter(workdir)\n",
    "    summary_writer.hparams(dict(config))\n",
    "\n",
    "    rng, init_rng = jax.random.split(rng)\n",
    "    state = create_train_state(init_rng, config)\n",
    "\n",
    "    for epoch in range(1, config.num_epochs + 1):\n",
    "        rng, input_rng = jax.random.split(rng)\n",
    "        state, train_loss, train_accuracy = train_epoch(state, train_ds,\n",
    "                                                        config.batch_size,\n",
    "                                                        input_rng)\n",
    "        _, test_loss, test_accuracy = apply_model(state, test_ds['image'],\n",
    "                                                  test_ds['label'])\n",
    "\n",
    "        logging.info(\n",
    "            'epoch:% 3d, train_loss: %.4f, train_accuracy: %.2f, test_loss: %.4f, test_accuracy: %.2f'\n",
    "            % (epoch, train_loss, train_accuracy * 100, test_loss,\n",
    "               test_accuracy * 100))\n",
    "\n",
    "        summary_writer.scalar('train_loss', train_loss, epoch)\n",
    "        summary_writer.scalar('train_accuracy', train_accuracy, epoch)\n",
    "        summary_writer.scalar('test_loss', test_loss, epoch)\n",
    "        summary_writer.scalar('test_accuracy', test_accuracy, epoch)\n",
    "\n",
    "    summary_writer.flush()\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a16194e-aba4-41a9-ad51-903beef9fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using jit decorator for GPU acceleration for entire function\n",
    "# @jax.jit\n",
    "# def train_step(optimizer, batch):\n",
    "#     def loss_fn(model):\n",
    "#         preds = model(batch['image'])\n",
    "#         loss = cross_entropy_loss(preds, batch['label'])\n",
    "#         return loss, preds\n",
    "#     grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "#     (_, preds), grad = grad_fn(optimizer.target)\n",
    "#     optimizer = optimizer.apply_gradient(grad)\n",
    "#     return optimizer\n",
    "\n",
    "# @jax.jit\n",
    "# def eval_step(model, batch):\n",
    "#     preds = model(batch['image'])\n",
    "#     return compute_metrics(preds, batch['label'])\n",
    "\n",
    "# def eval_model(model, test_ds):\n",
    "#     metrics = eval_step(model, test_ds)\n",
    "#     metrics = jax.device_get(metrics)\n",
    "#     summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "#     return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd998361-e903-4418-871f-d860f4f8fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
    "    ds_builder = tfds.builder('cifar10')\n",
    "    ds_builder.download_and_prepare()\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "    train_ds['image'] = jnp.float32(train_ds['image']) / 255.\n",
    "    test_ds['image'] = jnp.float32(test_ds['image']) / 255.\n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "050bd26f-297f-41e0-a44d-df7b899fade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(rng, config):\n",
    "    \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "    cnn = CNN()\n",
    "    params = cnn.init(rng, jnp.ones([1, 28, 28, 3]))['params']\n",
    "    tx = optax.sgd(config.learning_rate, config.momentum)\n",
    "    return train_state.TrainState.create(\n",
    "      apply_fn=cnn.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328e9b73-7b9e-4320-835e-99b3a70c765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0e8f34-7c8b-4ceb-9e5e-c2baa1b4fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 02:45:28.970445: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8014ac96-2327-4a77-8bb8-c9cecd27dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3e7eee3-9a13-4824-9768-2512ba2fa047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper functions for images.\n",
    "\n",
    "# def show_img(img, ax=None, title=None):\n",
    "#     \"\"\"Shows a single image.\"\"\"\n",
    "#     if ax is None:\n",
    "#         ax = plt.gca()\n",
    "#         ax.imshow(img[..., 0], cmap='gray')\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#     if title:\n",
    "#         ax.set_title(title)\n",
    "\n",
    "# def show_img_grid(imgs, titles):\n",
    "#     \"\"\"Shows a grid of images.\"\"\"\n",
    "#     n = int(np.ceil(len(imgs)**.5))\n",
    "#     _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
    "#     for i, (img, title) in enumerate(zip(imgs, titles)):\n",
    "#         show_img(img, axs[i // n][i % n], title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fdcaed8-e255-49dd-a5b9-a4c26b07034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_img_grid(\n",
    "#     [train_ds['image'][idx] for idx in range(25)],\n",
    "#     [f'label={train_ds[\"label\"][idx]}' for idx in range(25)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75ea9889-bb75-44d4-b0c3-7064e4dbd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs import default as config_lib\n",
    "config = config_lib.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9df9fd90-2f2f-4b01-a2e1-2365e315be95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sunilach/openflenv/lib/python3.8/site-packages/flax/core/scope.py:723: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  abs_value_flat = jax.tree_leaves(abs_value)\n",
      "/home/sunilach/openflenv/lib/python3.8/site-packages/flax/core/scope.py:724: FutureWarning: jax.tree_leaves is deprecated, and will be removed in a future release. Use jax.tree_util.tree_leaves instead.\n",
      "  value_flat = jax.tree_leaves(value)\n"
     ]
    }
   ],
   "source": [
    "config.num_epochs = 3\n",
    "models = {}\n",
    "for momentum in (0.8, 0.9, 0.95):\n",
    "    name = f'momentum={momentum}'\n",
    "    config.momentum = momentum\n",
    "    state = train_and_evaluate(config, workdir=f'./models/{name}')\n",
    "    models[name] = state.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45d5f4b5-54ae-47f3-8cc0-b85e1799d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all mistakes in testset.\n",
    "logits = CNN().apply({'params': state.params}, test_ds['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff0855f7-b857-4241-adaa-2a3909dd7e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0137"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_idxs, = jnp.where(test_ds['label'] != logits.argmax(axis=1))\n",
    "len(error_idxs) / len(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26c5900a-eed3-449d-9187-bd80d5559fe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_img_grid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshow_img_grid\u001b[49m(\n\u001b[1;32m      2\u001b[0m     [test_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m][idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m error_idxs[:\u001b[38;5;241m25\u001b[39m]],\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogits[idx]\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m error_idxs[:\u001b[38;5;241m25\u001b[39m]],\n\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show_img_grid' is not defined"
     ]
    }
   ],
   "source": [
    "show_img_grid(\n",
    "    [test_ds['image'][idx] for idx in error_idxs[:25]],\n",
    "    [f'pred={logits[idx].argmax()}' for idx in error_idxs[:25]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3efdfd-1566-4293-840d-d8651a91bb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7228f042-2167-46e8-a3d3-0edae1366765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed86c9-3bbb-4d7d-852d-61a6a1a1e59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0f83e-cdfa-4cf8-9cad-ca542bbe6541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed07904-602d-4afd-b3c1-ae58b9c6efa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f31f7b-51ed-4054-bb9f-227cb32ab7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf9a57-29c4-4787-bbd4-97553187b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LinearRegression:\n",
    "#     def __init__(self, n_feat: int) -> None:\n",
    "#         self.weights = jnp.ones(n_feat)\n",
    "    \n",
    "#     def mse(self, X, y) -> float:\n",
    "#         return mse_loss_function1(self.weights, X, y)\n",
    " \n",
    "#     def predict(self, X):\n",
    "#         return jnp.dot(X, self.weights)\n",
    "    \n",
    "#     def fit(self, X, Y, n_epochs : int, learning_rate : int, silent : bool) -> None:\n",
    "        \n",
    "#         # Speed up weight updates with consecutive calls to jitted `update` function.\n",
    "#         update_weights = jax.jit(update)\n",
    "        \n",
    "#         start_time = time.time()\n",
    "#         print('Training Loss at start: ', self.mse(X, Y))\n",
    "#         for i in range(n_epochs):\n",
    "#             self.weights = update_weights(self.weights, X, Y, learning_rate)\n",
    "#             if i % int(n_epochs/10) == 0 and not silent:\n",
    "#                 print(str(i), 'Training Loss: ', self.mse(X, Y))\n",
    "\n",
    "#         print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3cb180-67e4-4053-a940-6a745b2c4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, init_params = CNN().init_by_shape(random.PRNGKey(0), [((1, 32, 32, 3), jnp.float32)])\n",
    "model = nn.Model(CNN, init_params)\n",
    "optimizer = optim.Adam(learning_rate=learning_rate, beta1=beta, beta2 = beta_2).create(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3607c81f-ec04-4c09-9ee8-f5d921d100e9",
   "metadata": {},
   "source": [
    "#Jit Pre-compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7f487-1395-4ece-ac96-e054b21efca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(optimizer, train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da6014-7fb3-41b0-bbfa-01b7e5bd1f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(optimizer.target, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bbde3a-0caa-423a-a2b8-783f6e30e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_ds, test_ds, model, optimizer):\n",
    "\n",
    "    batch_size = 128\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "    beta = 0.9\n",
    "    beta_2 = 0.999\n",
    "    loss = 0\n",
    "    accuracy = 0\n",
    "    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_time = 0\n",
    "        start_time_3 = time.monotonic()\n",
    "        batch_gen = tfds.as_numpy(train_ds)\n",
    "        for batch in batch_gen:\n",
    "            start_time_step = time.monotonic()\n",
    "            optimizer = train_step(optimizer, batch)\n",
    "            train_time += time.monotonic() - start_time_step\n",
    "            \n",
    "        flax_step = time.monotonic() - start_time_3\n",
    "        \n",
    "        start_time_2 = time.monotonic()\n",
    "        loss, accuracy = eval_model(optimizer.target, test_ds)\n",
    "        flax_inf = time.monotonic() - start_time_2\n",
    "        \n",
    "        print('eval epoch: %d, epoch: %.2fs, actual_training: %.2fs, validation: %.2fs, loss: %.4f, accuracy: %.2f' % \n",
    "              (epoch, flax_step, train_time, flax_inf, loss, accuracy * 100))\n",
    "        \n",
    "    flax_time = time.monotonic() - start_time\n",
    "    return optimizer, flax_time, accuracy, flax_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfdb1ee-7a23-4ca2-ade5-f998cd0bfd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, flax_time, flax_acc, flax_inf = train(train_ds, test_ds, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25f87f-1a7a-49c5-a53b-9cb9d06dffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e8f7a-7acc-4615-afa5-67db3fb2da4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffd4d2d7-5537-496a-88c1-301da87d979c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# JAX Linear Regression with federation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf7090-da51-4f4e-9d28-2a5c6e3bca02",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Connect to a Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c0039-e1f7-4047-b98b-a2d4bd42f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'frontend'\n",
    "director_node_fqdn = 'localhost'\n",
    "director_port = 50050\n",
    "\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port,\n",
    "    tls=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815120e-b704-4a7d-a65a-3c7542023ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b011dd95-64a7-4a8b-91ec-e61cdf885bbb",
   "metadata": {},
   "source": [
    "### Initialize Data Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1985ac9-a2b1-4561-a962-6adfe35c3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment\n",
    "\n",
    "class LinearRegressionDataSet(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"Initialize DataLoader.\"\"\"\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        \"\"\"Return shard descriptor.\"\"\"\n",
    "        return self._shard_descriptor\n",
    "    \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "        \n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "        self.train_set = shard_descriptor.get_dataset('train')\n",
    "        self.val_set = shard_descriptor.get_dataset('val')\n",
    "        \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks with optimizer in contract.\"\"\"\n",
    "        return self.train_set\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"Output of this method will be provided to tasks without optimizer in contract.\"\"\"\n",
    "        return self.val_set\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"Information for aggregation.\"\"\"\n",
    "        return len(self.val_set)\n",
    "    \n",
    "lin_reg_dataset = LinearRegressionDataSet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8909127-99d1-4dba-86fe-01a1b86585e7",
   "metadata": {},
   "source": [
    "### Define Model Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523c9a2-a259-461f-937f-1fb054bd2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_adapter = 'custom_adapter.CustomFrameworkAdapter'\n",
    "\n",
    "# LinearRegression class accepts a parameter n_features. Should be same as `sample_shape` from `director_config.yaml`\n",
    "fed_model = LinearRegression(1)\n",
    "MI = ModelInterface(model=fed_model, optimizer=None, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = LinearRegression(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3558bb-b21b-48ac-b07e-43cf75e6907b",
   "metadata": {},
   "source": [
    "### Register Tasks\n",
    "We need to employ a trick reporting metrics. OpenFL decides which model is the best based on an *increasing* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e1ff9-d54a-49b5-9ce8-8bc72c6a2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "@TI.add_kwargs(**{'lr': 0.01,\n",
    "                   'epochs': 101})\n",
    "@TI.register_fl_task(model='my_model', data_loader='train_data', \\\n",
    "                     device='device', optimizer='optimizer')     \n",
    "def train(my_model, train_data, optimizer, device, lr, epochs):\n",
    "    X, Y = train_data[:,:-1], train_data[:,-1]\n",
    "    my_model.fit(X, Y, epochs, lr, silent=False)\n",
    "    return {'train_MSE': my_model.mse(X, Y),}\n",
    "\n",
    "@TI.register_fl_task(model='my_model', data_loader='val_data', device='device')\n",
    "def validate(my_model, val_data, device):\n",
    "    X, Y = val_data[:,:-1], val_data[:,-1] \n",
    "    return {'validation_MSE': my_model.mse(X, Y),}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7659cc-6e03-43f5-9078-95707fa0e4d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749100e8-05ce-418c-a980-545e3beb900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'jax_linear_regression_experiment'\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf1df7-8ca8-4a5e-a833-47c265c11e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_experiment.start(model_provider=MI,\n",
    "                    task_keeper=TI,\n",
    "                    data_loader=lin_reg_dataset,\n",
    "                    rounds_to_train=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1178d1ea-05e6-46be-ac07-21620bd6ec76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fl_experiment.stream_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23cac5-caec-4161-b4b2-dddceb3eab80",
   "metadata": {
    "tags": []
   },
   "source": [
    "# JAX Linear Regression without federation (Optional Simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94be17d7-90c9-4e5f-aeb1-102271826370",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ced27-a808-4eca-be6e-d8b62929f32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports for running JAX Linear Regression example without OpenFL.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7, 5\n",
    "\n",
    "from jax import make_jaxpr\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58128c30-7865-4412-b4fd-86b0fe53f1a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Simple Linear Regression\n",
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/01/eq5-1.png\" width=\"500\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140705fc-4af3-4668-a26b-2ebe2d42575e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create a dataset with n_features\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=10, random_state=42)\n",
    "\n",
    "# Train test split - Default 0.75/0.25\n",
    "X, X_test, y, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2665d0b-78ce-4caf-a4ca-a9decffaa96f",
   "metadata": {},
   "source": [
    "Visualize data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5afbf-e010-4d4a-bb92-46de06d39866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe555dd-9e8d-4e80-bfde-87e3cafac14c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a7ddb3-166e-447f-a8f1-881511cfbd9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JAX logical execution plan\n",
    "print(jax.make_jaxpr(update)(jnp.ones(X.shape[1]), X, y, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574bac29-b5c2-4f41-8655-e98450fdef8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X.shape -> (n_samples, n_features)\n",
    "\n",
    "lr_model = LinearRegression(X.shape[1])\n",
    "lr = 0.01\n",
    "epochs = 101\n",
    "\n",
    "print(f\"Initial Test MSE: {lr_model.mse(X_test,y_test)}\")\n",
    "\n",
    "# silent: logging verbosity\n",
    "lr_model.fit(X,y, epochs, lr, silent=False)\n",
    "\n",
    "print(f\"Final Test MSE: {lr_model.mse(X_test,y_test)}\")\n",
    "\n",
    "print(f\"Final parameters: {lr_model.weights}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
